{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv(\"../data/AAPL_05222012_0930_1300_LOB_2.csv\", index_col='Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = [name.split(\"..\")[0].split(\".\")[1].lower() for name in data_raw.columns.values if len(name) > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_raw.columns = [\"Time\"] + cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>bid_price1</th>\n",
       "      <th>bid_update_time1</th>\n",
       "      <th>bid_size1</th>\n",
       "      <th>ask_price1</th>\n",
       "      <th>ask_update_time1</th>\n",
       "      <th>ask_size1</th>\n",
       "      <th>bid_price2</th>\n",
       "      <th>bid_update_time2</th>\n",
       "      <th>bid_size2</th>\n",
       "      <th>...</th>\n",
       "      <th>bid_size9</th>\n",
       "      <th>ask_price9</th>\n",
       "      <th>ask_update_time9</th>\n",
       "      <th>ask_size9</th>\n",
       "      <th>bid_price10</th>\n",
       "      <th>bid_update_time10</th>\n",
       "      <th>bid_size10</th>\n",
       "      <th>ask_price10</th>\n",
       "      <th>ask_update_time10</th>\n",
       "      <th>ask_size10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012/05/22 09:30:00.000</td>\n",
       "      <td>569.02</td>\n",
       "      <td>2012/05/22 09:29:34.006</td>\n",
       "      <td>40</td>\n",
       "      <td>570</td>\n",
       "      <td>2012/05/22 09:29:43.573</td>\n",
       "      <td>400</td>\n",
       "      <td>568.80</td>\n",
       "      <td>2012/05/22 09:29:47.563</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>571.00</td>\n",
       "      <td>2012/05/22 09:29:49.424</td>\n",
       "      <td>120</td>\n",
       "      <td>567.16</td>\n",
       "      <td>2012/05/22 09:28:28.730</td>\n",
       "      <td>60</td>\n",
       "      <td>571.24</td>\n",
       "      <td>2012/05/22 08:13:36.797</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012/05/22 09:30:00.003</td>\n",
       "      <td>569.02</td>\n",
       "      <td>2012/05/22 09:29:34.006</td>\n",
       "      <td>40</td>\n",
       "      <td>570</td>\n",
       "      <td>2012/05/22 09:29:43.573</td>\n",
       "      <td>400</td>\n",
       "      <td>568.80</td>\n",
       "      <td>2012/05/22 09:29:47.563</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>570.99</td>\n",
       "      <td>2012/05/22 09:29:53.347</td>\n",
       "      <td>200</td>\n",
       "      <td>567.16</td>\n",
       "      <td>2012/05/22 09:28:28.730</td>\n",
       "      <td>60</td>\n",
       "      <td>571.00</td>\n",
       "      <td>2012/05/22 09:29:49.424</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012/05/22 09:30:00.003</td>\n",
       "      <td>569.02</td>\n",
       "      <td>2012/05/22 09:29:34.006</td>\n",
       "      <td>40</td>\n",
       "      <td>570</td>\n",
       "      <td>2012/05/22 09:29:43.573</td>\n",
       "      <td>400</td>\n",
       "      <td>568.80</td>\n",
       "      <td>2012/05/22 09:29:47.563</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>570.67</td>\n",
       "      <td>2012/05/22 09:29:29.034</td>\n",
       "      <td>10</td>\n",
       "      <td>567.16</td>\n",
       "      <td>2012/05/22 09:28:28.730</td>\n",
       "      <td>60</td>\n",
       "      <td>570.99</td>\n",
       "      <td>2012/05/22 09:29:53.347</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012/05/22 09:30:00.003</td>\n",
       "      <td>569.03</td>\n",
       "      <td>2012/05/22 09:30:00.003</td>\n",
       "      <td>8</td>\n",
       "      <td>570</td>\n",
       "      <td>2012/05/22 09:29:43.573</td>\n",
       "      <td>400</td>\n",
       "      <td>569.02</td>\n",
       "      <td>2012/05/22 09:29:34.006</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>570.67</td>\n",
       "      <td>2012/05/22 09:29:29.034</td>\n",
       "      <td>10</td>\n",
       "      <td>567.30</td>\n",
       "      <td>2012/05/22 09:29:38.985</td>\n",
       "      <td>200</td>\n",
       "      <td>570.99</td>\n",
       "      <td>2012/05/22 09:29:53.347</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012/05/22 09:30:00.003</td>\n",
       "      <td>569.03</td>\n",
       "      <td>2012/05/22 09:30:00.003</td>\n",
       "      <td>8</td>\n",
       "      <td>570</td>\n",
       "      <td>2012/05/22 09:29:43.573</td>\n",
       "      <td>400</td>\n",
       "      <td>569.02</td>\n",
       "      <td>2012/05/22 09:29:34.006</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>570.55</td>\n",
       "      <td>2012/05/22 09:30:00.003</td>\n",
       "      <td>8</td>\n",
       "      <td>567.30</td>\n",
       "      <td>2012/05/22 09:29:38.985</td>\n",
       "      <td>200</td>\n",
       "      <td>570.67</td>\n",
       "      <td>2012/05/22 09:29:29.034</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Time  bid_price1         bid_update_time1  \\\n",
       "Index                                                                 \n",
       "1      2012/05/22 09:30:00.000      569.02  2012/05/22 09:29:34.006   \n",
       "2      2012/05/22 09:30:00.003      569.02  2012/05/22 09:29:34.006   \n",
       "3      2012/05/22 09:30:00.003      569.02  2012/05/22 09:29:34.006   \n",
       "4      2012/05/22 09:30:00.003      569.03  2012/05/22 09:30:00.003   \n",
       "5      2012/05/22 09:30:00.003      569.03  2012/05/22 09:30:00.003   \n",
       "\n",
       "       bid_size1  ask_price1         ask_update_time1  ask_size1  bid_price2  \\\n",
       "Index                                                                          \n",
       "1             40         570  2012/05/22 09:29:43.573        400      568.80   \n",
       "2             40         570  2012/05/22 09:29:43.573        400      568.80   \n",
       "3             40         570  2012/05/22 09:29:43.573        400      568.80   \n",
       "4              8         570  2012/05/22 09:29:43.573        400      569.02   \n",
       "5              8         570  2012/05/22 09:29:43.573        400      569.02   \n",
       "\n",
       "              bid_update_time2  bid_size2     ...      bid_size9 ask_price9  \\\n",
       "Index                                         ...                             \n",
       "1      2012/05/22 09:29:47.563        100     ...            200     571.00   \n",
       "2      2012/05/22 09:29:47.563        100     ...            200     570.99   \n",
       "3      2012/05/22 09:29:47.563        100     ...            200     570.67   \n",
       "4      2012/05/22 09:29:34.006         40     ...            200     570.67   \n",
       "5      2012/05/22 09:29:34.006         40     ...            200     570.55   \n",
       "\n",
       "              ask_update_time9  ask_size9 bid_price10  \\\n",
       "Index                                                   \n",
       "1      2012/05/22 09:29:49.424        120      567.16   \n",
       "2      2012/05/22 09:29:53.347        200      567.16   \n",
       "3      2012/05/22 09:29:29.034         10      567.16   \n",
       "4      2012/05/22 09:29:29.034         10      567.30   \n",
       "5      2012/05/22 09:30:00.003          8      567.30   \n",
       "\n",
       "             bid_update_time10  bid_size10 ask_price10  \\\n",
       "Index                                                    \n",
       "1      2012/05/22 09:28:28.730          60      571.24   \n",
       "2      2012/05/22 09:28:28.730          60      571.00   \n",
       "3      2012/05/22 09:28:28.730          60      570.99   \n",
       "4      2012/05/22 09:29:38.985         200      570.99   \n",
       "5      2012/05/22 09:29:38.985         200      570.67   \n",
       "\n",
       "             ask_update_time10  ask_size10  \n",
       "Index                                       \n",
       "1      2012/05/22 08:13:36.797         200  \n",
       "2      2012/05/22 09:29:49.424         120  \n",
       "3      2012/05/22 09:29:53.347         200  \n",
       "4      2012/05/22 09:29:53.347         200  \n",
       "5      2012/05/22 09:29:29.034          10  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_raw.to_csv(\"../data/AAPL_LOB.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imp import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from label import mid_label, spread_label\n",
    "from basic_set import get_basic\n",
    "from insensitive_set import get_spread_midprice, get_price_diff, get_mean, get_accumulated_diff\n",
    "from sensitive_set import get_derivatives\n",
    "from sampling import sampling_labels\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier as RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv('../data/AAPL_LOB.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_data_tinsen(data_raw):\n",
    "    spreads_mids = get_spread_midprice(data_raw)\n",
    "    price_diff = get_price_diff(data_raw)\n",
    "    means = get_mean(data_raw)\n",
    "    accum_diff = get_accumulated_diff(data_raw)\n",
    "    data_tfm = pd.merge(spreads_mids, price_diff, on = ['Index', 'Time'])\n",
    "    data_tfm = pd.merge(data_tfm, means, on = ['Index', 'Time'])\n",
    "    data_tfm = pd.merge(data_tfm, accum_diff, on = ['Index', 'Time'])\n",
    "    return(data_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_data(data_raw, feature_basic = True, feature_tinsen = True, feature_tsen = True, delta_t = 30):\n",
    "    if feature_basic * feature_tinsen * feature_tsen:\n",
    "        basics = get_basic(data_raw)\n",
    "        data_tinsen = transform_data_tinsen(data_raw)\n",
    "        data_tsen = get_derivatives(data_raw, delta_t)\n",
    "        basics = basics.iloc[delta_t:]\n",
    "        data_tinsen = data_tinsen.iloc[delta_t:]\n",
    "        #print(\"basics_ind:\" + str(basics.index[:5]) + \"tinsen: \"+ str(data_tinsen.index[:5]) + str(data_tsen.index[:5]))\n",
    "        data_tfm = pd.merge(basics, data_tinsen, on = ['Index', 'Time'])\n",
    "        data_tfm = pd.merge(data_tfm, data_tsen, on = ['Index', 'Time'])\n",
    "        return(data_tfm)\n",
    "    elif (feature_basic == True) and (feature_tinsen == True):\n",
    "        basics = get_basic(data_raw)\n",
    "        data_tinsen = transform_data_tinsen(data_raw)\n",
    "        data_tfm = pd.merge(basics, data_tinsen, on = ['Index', 'Time'])\n",
    "        return(data_tfm)\n",
    "    elif (feature_basic == True):\n",
    "        basics = get_basic(data_raw)\n",
    "        return(basics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_rawdata(data_raw, split_time = datetime(2012, 5, 22, 11, 0)):\n",
    "    time = np.array([datetime.strptime(time, \"%Y/%m/%d %H:%M:%S.%f\") for time in data_raw['Time']])\n",
    "    train_index = time < datetime(2012, 5, 22, 11, 0)\n",
    "    train = data_raw.iloc[train_index]\n",
    "    test = data_raw.iloc[np.logical_not(train_index)]\n",
    "    return({\"train\": train, \"test\": test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data_sets = split_rawdata(data_raw)\n",
    "train = raw_data_sets[\"train\"]\n",
    "test = raw_data_sets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_tfm = transform_data(train, delta_t = 20)\n",
    "test_tfm = transform_data(test, delta_t = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203299, 128)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_tfm.head()\n",
    "train_tfm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare y labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mid price based on delta_t = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***try without sampling***\n",
    "\n",
    "Just use ~50% for training, ~25% for validating and ~25% for testing within the 9-11am dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# did not use\n",
    "def get_sampling_labels_ind(train, test, sample_type = \"mid\", delta_t = 20, sample_size_train = 2000, sample_size_test = 10000, tick_size = 0.01,\\\n",
    "                           train_sample_random=False, test_sample_random = True, up_prob_train = 1/3, down_prob_train = 1/3,\\\n",
    "                           up_prob_test = 1/3, down_prob_test = 1/3):\n",
    "    if sample_type == \"mid\":\n",
    "        y_lab_train_all = mid_label(train, delta_t, tick_size)\n",
    "        y_lab_test_all = mid_label(test, delta_t, tick_size)\n",
    "        t_ind = sampling_labels(y_lab_train_all, sample_size_train, sample_random = train_sample_random, up_prob = up_prob_train, down_prob = down_prob_train)\n",
    "        v_ind = sampling_labels(y_lab_test_all, sample_size_test, sample_random = test_sample_random, up_prob = up_prob_test, down_prob = down_prob_test)\n",
    "#         y_lab_train = [y_lab_train_all[i] for i in range(len(t_ind)) if t_ind[i]]\n",
    "#         y_lab_test = [y_lab_test_all[i] for i in range(len(v_ind)) if v_ind[i]]\n",
    "        y_lab_train = pd.Series(y_lab_train_all).iloc[t_ind]\n",
    "        y_lab_test = pd.Series(y_lab_test_all).iloc[v_ind]\n",
    "        return({\"y_lab_train\": y_lab_train, \"y_lab_test\": y_lab_test, \"t_ind\": t_ind, \"v_ind\": v_ind})\n",
    "    else:\n",
    "        y_lab_train_all = spread_label(train, delta_t = delta_t)\n",
    "        y_lab_test_all = spread_label(test, delta_t = delta_t)\n",
    "        t_ind = sampling_labels(y_lab_train_all, sample_size_train, sample_random = train_sample_random, up_prob = up_prob_train, down_prob = down_prob_train)\n",
    "        v_ind = sampling_labels(y_lab_test_all, sample_size_test, sample_random = test_sample_random, up_prob = up_prob_test, down_prob = down_prob_test)\n",
    "#         y_lab_train = [y_lab_train_all[i] for i in range(len(t_ind)) if t_ind[i]]\n",
    "#         y_lab_test = [y_lab_test_all[i] for i in range(len(v_ind)) if v_ind[i]]\n",
    "        y_lab_train = pd.Series(y_lab_train_all).iloc[t_ind]\n",
    "        y_lab_test = pd.Series(y_lab_test_all).iloc[v_ind]\n",
    "        return({\"y_lab_train\": y_lab_train, \"y_lab_test\": y_lab_test, \"t_ind\": t_ind, \"v_ind\": v_ind})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# did not use\n",
    "samples_inds = get_sampling_labels_ind(train_tfm, test_tfm, sample_type = \"mid\", delta_t = 30, tick_size = 0.04,\\\n",
    "                                      train_sample_random=False, test_sample_random = False, up_prob_train = 0.45, \\\n",
    "                                      down_prob_train = 0.45,sample_size_train = 10000, sample_size_test = 10000, \\\n",
    "                                             up_prob_test = 1/3, down_prob_test = 1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# did not use\n",
    "y_mid_train = samples_inds[\"y_lab_train\"]\n",
    "y_mid_test = samples_inds[\"y_lab_test\"]\n",
    "t_ind = samples_inds[\"t_ind\"]\n",
    "v_ind = samples_inds[\"v_ind\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "down          1700\n",
       "stationary    6528\n",
       "up            1772\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# did not use\n",
    "y_mid_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# did not use\n",
    "train_samples_inds = get_sampling_labels_ind(train_tfm, train_tfm, sample_type = \"mid\", delta_t = 30, tick_size = 0.04,\\\n",
    "                                      train_sample_random=False, test_sample_random = False, up_prob_train = 1/3, \\\n",
    "                                      down_prob_train = 1/3,sample_size_train = 5000, sample_size_test = 5000, \\\n",
    "                                             up_prob_test = 1/3, down_prob_test = 1/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# did not use\n",
    "y_mid_train_train = train_samples_inds[\"y_lab_train\"]\n",
    "y_mid_train_test = train_samples_inds[\"y_lab_test\"]\n",
    "t_ind = train_samples_inds[\"t_ind\"]\n",
    "v_ind = train_samples_inds[\"v_ind\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203329,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lab_train_all = mid_label(train, 20, 0.01)\n",
    "y_lab_train_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129304,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lab_test_all = mid_label(test, 20, 0.01)\n",
    "y_lab_test_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stationary    194130\n",
       "up              4924\n",
       "down            4245\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lab_train_all = spread_label(train, delta_t = 50)\n",
    "y_lab_train_all.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stationary    126053\n",
       "down            1706\n",
       "up              1515\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lab_test_all = spread_label(test, 50)\n",
    "y_lab_test_all.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = np.arange(train_tfm.shape[0])\n",
    "np.random.seed(0)\n",
    "# Shuffle the index and separate the data into train(50%), validation(25%), and test(25%) set.\n",
    "np.random.shuffle(index)\n",
    "\n",
    "# approximate subset\n",
    "train_x = train_tfm.iloc[index[0:101659]]\n",
    "validation_x = train_tfm.iloc[index[101659:152489]]\n",
    "test_x = train_tfm.iloc[index[152489:]]\n",
    "\n",
    "train_y = y_lab_train_all.iloc[index[0:101659]]\n",
    "validation_y = y_lab_train_all.iloc[index[101659:152489]]\n",
    "test_y = y_lab_train_all.iloc[index[152489:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101659, 128)\n",
      "(50830, 128)\n",
      "(50840, 128)\n",
      "(101659,)\n",
      "(50830,)\n",
      "(50840,)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape)\n",
    "print(validation_x.shape)\n",
    "print(test_x.shape)\n",
    "print(train_y.shape)\n",
    "print(validation_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1e-05, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(C=100, gamma=10**-5, decision_function_shape='ovr')\n",
    "clf.fit(train_x[train_x.columns[2:]].iloc[:10000], train_y[:10000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99990000000000001"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(train_x[train_x.columns[2:]].iloc[:10000], train_y[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95630000000000004"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(validation_x[validation_x.columns[2:]].iloc[:10000], validation_y[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95809999999999995"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_x[test_x.columns[2:]].iloc[:10000], test_y[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3639,    5,    0],\n",
       "       [   0, 2493,    0],\n",
       "       [   1,    1, 3861]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test = clf.predict(train_x[train_x.columns[2:]].iloc[:10000])\n",
    "confusion_matrix(predict_test, train_y[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  20,   12,    0],\n",
       "       [ 196, 9498,  216],\n",
       "       [   0,   13,   45]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test = clf.predict(validation_x[validation_x.columns[2:]].iloc[:10000])\n",
    "confusion_matrix(predict_test, validation_y[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  33,    2,    1],\n",
       "       [   1,   64,    0],\n",
       "       [3470, 2490, 3939]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test = clf.predict(test_x[test_x.columns[2:]].iloc[:10000])\n",
    "confusion_matrix(predict_test, test_y[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97999999999999998"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_tfm[test_tfm.columns[2:]].iloc[:10000], y_lab_test_all[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_test = clf.predict(test_tfm[test_tfm.columns[2:]].iloc[:10000])\n",
    "CM = confusion_matrix(predict_test, y_lab_test_all[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0],\n",
       "       [ 113, 9800,   87],\n",
       "       [   0,    0,    0]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Up</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stationary</th>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.989899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Down</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Precision  Recall  F1_Measure\n",
       "Up                  0     NaN         NaN\n",
       "Stationary          1    0.98    0.989899\n",
       "Down                0     NaN         NaN"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_measure(CM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mid-price can get OK results... but spread crossing is so bad because even if delta t is 50 or 100, there are still so few non-stationaries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99911468733707787"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_depth=10 or 20, seems plenty good\n",
    "cand = RF(n_estimators=500, max_depth=20, max_features='sqrt')\n",
    "cand = cand.fit(train_x[train_x.columns[2:]], train_y)\n",
    "# accuracy\n",
    "cand.score(train_x[train_x.columns[2:]], train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98199881959472757"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand.score(validation_x[validation_x.columns[2:]], validation_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9829858379228954"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand.score(test_x[test_x.columns[2:]], test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96519028947510888"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand.score(test_tfm[test_tfm.columns[2:]].iloc[:-1], y_lab_test_all[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15915,   198,    15],\n",
       "       [  223, 17086,   237],\n",
       "       [   37,   205, 16914]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = cand.predict(validation_x[validation_x.columns[2:]])\n",
    "confusion_matrix(prediction, validation_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_test = cand.predict(test_tfm[test_tfm.columns[2:]].iloc[:-1])\n",
    "CM = confusion_matrix(predict_test, y_lab_test_all[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34331,   995,   166],\n",
       "       [ 1046, 53355,  1123],\n",
       "       [  158,  1013, 37116]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cal_measure(CM):\n",
    "    '''\n",
    "    input: 3 by 3 confusion matrix\n",
    "    output: data frame of measurements\n",
    "    '''\n",
    "    # for Up (0)\n",
    "    up = np.array([[CM[0,0],(CM[0,1]+CM[0,2])],[(CM[1,0]+CM[2,0]),(CM[1,1]+CM[2,2]+CM[1,2]+CM[2,1])]], dtype='float')\n",
    "    station = np.array([[CM[1,1],(CM[1,0]+CM[1,2])],[(CM[0,1]+CM[2,1]),(CM[0,0]+CM[2,2]+CM[0,2]+CM[2,0])]], dtype='float')\n",
    "    down = np.array([[CM[2,2],(CM[2,0]+CM[2,1])],[(CM[0,2]+CM[1,2]),(CM[0,0]+CM[1,1]+CM[0,1]+CM[1,0])]], dtype='float')\n",
    "    p_up = up[0,0]/(up[0,0]+up[1,0])\n",
    "    p_station = station[0,0]/(station[0,0]+station[1,0])\n",
    "    p_down = down[0,0]/(down[0,0]+down[1,0])\n",
    "    r_up = up[0,0]/(up[0,0]+up[0,1])\n",
    "    r_station = station[0,0]/(station[0,0]+station[0,1])\n",
    "    r_down = down[0,0]/(down[0,0]+down[0,1])\n",
    "    f_up = 2*p_up*r_up/(p_up+r_up)\n",
    "    f_station = 2*p_station*r_station/(p_station+r_station)\n",
    "    f_down = 2*p_down*r_down/(p_down+r_down)\n",
    "    measure=pd.DataFrame(index=['Up','Stationary','Down'])\n",
    "    measure['Precision'] = [p_up,p_station,p_down]\n",
    "    measure['Recall'] = [r_up,r_station,r_down]\n",
    "    measure['F1_Measure'] = [f_up,f_station,f_down]\n",
    "    return measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_Measure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Up</th>\n",
       "      <td>0.966118</td>\n",
       "      <td>0.967288</td>\n",
       "      <td>0.966703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stationary</th>\n",
       "      <td>0.963730</td>\n",
       "      <td>0.960936</td>\n",
       "      <td>0.962331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Down</th>\n",
       "      <td>0.966437</td>\n",
       "      <td>0.969415</td>\n",
       "      <td>0.967924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Precision    Recall  F1_Measure\n",
       "Up           0.966118  0.967288    0.966703\n",
       "Stationary   0.963730  0.960936    0.962331\n",
       "Down         0.966437  0.969415    0.967924"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_measure(CM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
